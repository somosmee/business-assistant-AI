{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "from string import punctuation\n",
    "from nltk.stem import RSLPStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "clf = MultinomialNB()\n",
    "nlp = spacy.load('pt')\n",
    "stemmer = RSLPStemmer()\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "     # sales\n",
    "     ['vendas do último mês', 'sales'],\n",
    "     ['quanto vendi esse mês', 'sales'],\n",
    "     ['quanto vendi no mês de agosto', 'sales'],\n",
    "     ['quais são os 10 produtos que mais vendi esse ano', 'sales'],\n",
    "     ['quais são os 10 produtos que mais vendi esse mês', 'sales'],\n",
    "     ['quais são os 10 produtos que mais vendi hoje', 'sales'],\n",
    "     ['qual produto eu mais vendi hoje', 'sales'],\n",
    "     # products\n",
    "     ['quantos produtos eu tenho na minha base', 'products'],\n",
    "     ['quantos produtos eu tenho na minha base de dados', 'products'],\n",
    "     ['quantos produtos eu tenho na minha loja', 'products'],\n",
    "     ['quantos refrigerantes eu vendo na minha loja', 'products'],\n",
    "     ['quanto é o preço da coca-cola', 'products'],\n",
    "     ['qual é o preço da coca-cola', 'products'],\n",
    "     ['quantos refrigerantes tenho no estoque', 'products']\n",
    " ], columns=['message', 'label'])\n",
    "\n",
    "'''\n",
    " PREPROCESSING TEXT\n",
    "'''\n",
    "\n",
    "def normalize(message):\n",
    "    normalized = unicodedata.normalize('NFKD', message).encode('ASCII', 'ignore').decode('utf-8')\n",
    "    return normalized\n",
    "\n",
    "def stem(message):\n",
    "    words = word_tokenize(message)\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def remove_stopwords(message):\n",
    "    blacklist = set(stopwords.words('portuguese') + list(punctuation))\n",
    "    clean_words = [word for word in word_tokenize(message) if word not in blacklist]\n",
    "    return ' '.join(clean_words)\n",
    "\n",
    "def preprocess_message(message):\n",
    "    message = normalize(message)\n",
    "    message = remove_stopwords(message)\n",
    "#     message = stem(message)\n",
    "    return message\n",
    "\n",
    "def preprocess(df, column_in='message', column_out='message_clean'):\n",
    "    df[column_out] = df[column_in].apply(lambda message : preprocess_message(message))\n",
    "\n",
    "'''\n",
    " VECTORIZE\n",
    "'''\n",
    "def vectorize(df, column = 'message'):\n",
    "    X = vectorizer.fit_transform(df[column])\n",
    "    return X\n",
    "\n",
    "def vectorize_message(message):\n",
    "    return vectorizer.transform([message])\n",
    "\n",
    "'''\n",
    " PREDICTION\n",
    "'''\n",
    "def predict(model, message):\n",
    "    vector = vectorize_message(message)\n",
    "    predict_label = model.predict(vector)\n",
    "    predict_proba = model.predict_proba(vector)\n",
    "    return { 'label': predict_label, 'probability': predict_proba, 'classes': model.classes_ }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', 'agosto', 'ano', 'base', 'coca', 'cola', 'dados', 'estoque', 'hoje', 'loja', 'mes', 'preco', 'produto', 'produtos', 'quais', 'quanto', 'quantos', 'refrigerantes', 'sao', 'ultimo', 'vendas', 'vendi', 'vendo']\n",
      "corpus shape:  (14, 23)\n"
     ]
    }
   ],
   "source": [
    "preprocess(df, column_in='message', column_out='message_clean')\n",
    "X = vectorize(df, column='message_clean')\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print('corpus shape: ', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.fit(X, df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': array(['products'], dtype='<U8'),\n",
       " 'probability': array([[0.71838278, 0.28161722]]),\n",
       " 'classes': array(['products', 'sales'], dtype='<U8')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'quantas coca-colas tenho no estoque?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n",
    "\n",
    "Named Entities supported by Spacy: https://spacy.io/api/annotation#named-entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maria PER\n",
      "Paris LOC\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Maria está se mudando para Paris. No dia 01/02/2019 ela irá partir.')\n",
    "for entidade in doc.ents:\n",
    "    print(entidade.text, entidade.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Maria\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " está se mudando para \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Paris\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". No dia 01/02/2019 ela irá partir.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Named person or family.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('PER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos aqui que o Spacy não identificou a data. Então vamos treinar um modelo para que isso seja possível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'pt'\n",
      "Losses {'ner': 27.490759546630343}\n",
      "Losses {'ner': 35.42058718498639}\n",
      "Losses {'ner': 15.506918851121213}\n",
      "Losses {'ner': 23.31801952333217}\n",
      "Losses {'ner': 18.023392192993924}\n",
      "Losses {'ner': 19.650847862412775}\n",
      "Losses {'ner': 21.60367745428107}\n",
      "Losses {'ner': 20.66616348864045}\n",
      "Losses {'ner': 18.14009229358635}\n",
      "Losses {'ner': 21.078436665222398}\n",
      "Losses {'ner': 18.903406301404175}\n",
      "Losses {'ner': 21.48789181606662}\n",
      "Losses {'ner': 14.439496162929572}\n",
      "Losses {'ner': 15.32623327759211}\n",
      "Losses {'ner': 18.812756245024502}\n",
      "Losses {'ner': 20.415693648981687}\n",
      "Losses {'ner': 15.088580413488671}\n",
      "Losses {'ner': 12.45081877951452}\n",
      "Losses {'ner': 14.515449170852662}\n",
      "Losses {'ner': 13.827697296379483}\n",
      "Losses {'ner': 17.705478971038247}\n",
      "Losses {'ner': 15.181215309741674}\n",
      "Losses {'ner': 17.6580340828732}\n",
      "Losses {'ner': 16.939349999211117}\n",
      "Losses {'ner': 13.074150303346073}\n",
      "Losses {'ner': 19.621065201893543}\n",
      "Losses {'ner': 25.998893824154948}\n",
      "Losses {'ner': 22.043855502881343}\n",
      "Losses {'ner': 11.22873096479995}\n",
      "Losses {'ner': 14.23800224655588}\n",
      "Entities in 'quero meu relatório de vendas entre 01/02/2020 e 01/03/2020'\n",
      "MISC quero\n",
      "DATE 01/03/2020\n",
      "Saved model to modelo_kodama.md\n",
      "Loading from modelo_kodama.md\n",
      "MISC quero\n",
      "DATE 01/03/2020\n"
     ]
    }
   ],
   "source": [
    "# treinar o modelo com os novos dados\n",
    "!python train_new_entity_type.py -m pt -o modelo_kodama.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('./modelo_kodama.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    quero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " meu relatório de vendas entre 01/02/2020 e \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    01/03/2020\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp('quero meu relatório de vendas entre 01/02/2020 e 01/03/2020')\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós podemos observar que com um modelo probabislítico temos alguns problemas em identificar datas. Precisamos de mais exemplos e talvez nesse caso seja mais interessante utilizar uma abordagem baseda em regras (regex) e no caso de dados relativas como \"ultimo mes\" \"semestre de 2020\" podemos utilizar uma abordagem combinada com regras e bases de conhecimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule based and Knowledge Based\n",
    "\n",
    "https://spacy.io/usage/rule-based-matching\n",
    "https://spacy.io/usage/rule-based-matching#entityruler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mês', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.pt import Portuguese\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "nlp = Portuguese() # if you want to combina with existing prob model use spacy.load('pt')\n",
    "ruler = EntityRuler(nlp)\n",
    "patterns = [{'label': 'DATE', 'pattern': 'mês', 'id': 'date'}]\n",
    "ruler.add_patterns(patterns)\n",
    "nlp.add_pipe(ruler)\n",
    "\n",
    "doc = nlp(\"quero relatório de vendas do ultimo mês\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "# nlp.to_disk(\"/path/to/model\") saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
